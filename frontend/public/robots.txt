# ============================================================================
# robots.txt for Protocol Soup
# https://protocolsoup.com
# ============================================================================

# ----------------------------------------------------------------------------
# Default: Allow everything for search engines
# ----------------------------------------------------------------------------
User-agent: *
Allow: /

# Allow frontend data APIs so Googlebot can render protocol pages
# (more specific rules take precedence over the broader Disallow)
Allow: /api/protocols/
Allow: /api/protocols$

# Block all other backend API/protocol endpoints
Disallow: /api/
Disallow: /ws/
Disallow: /oauth2/
Disallow: /oidc/
Disallow: /saml/
Disallow: /spiffe/
Disallow: /scim/
Disallow: /ssf/
Disallow: /callback

# ----------------------------------------------------------------------------
# AI Training Crawlers
# ----------------------------------------------------------------------------
User-agent: GPTBot
Allow: /

User-agent: ChatGPT-User
Allow: /

User-agent: ClaudeBot
Allow: /

User-agent: anthropic-ai
Allow: /

User-agent: Google-Extended
Allow: /

User-agent: CCBot
Disallow: /

User-agent: meta-externalagent
Disallow: /

User-agent: Amazonbot
Disallow: /

User-agent: Applebot-Extended
Disallow: /

User-agent: Bytespider
Disallow: /

User-agent: cohere-ai
Disallow: /

User-agent: PerplexityBot
Disallow: /

User-agent: YouBot
Disallow: /

User-agent: Diffbot
Disallow: /

# ----------------------------------------------------------------------------
# Sitemap
# ----------------------------------------------------------------------------
Sitemap: https://protocolsoup.com/sitemap.xml
